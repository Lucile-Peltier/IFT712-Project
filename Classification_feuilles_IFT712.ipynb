{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet de session : Classification de feuilles\n",
    "\n",
    "## Lucile Peltier (pell3601), Sergio Redondo (reds2401)\n",
    "\n",
    "## IFT712 - Université de Sherbrooke\n",
    "\n",
    "# Objectif :\n",
    "\n",
    "Tester des méthodes de classification sur une base de données Kaggle, tout en respectant l’utilisation de validation croisée, et de recherche d’hyperparamètres afin d’identifier la meilleure solution.\n",
    "\n",
    "Base de données : https://www.kaggle.com/c/leaf-classification/\n",
    "\n",
    "Méthodes à tester : machines à vecteurs de support (SVM), k-plus proches voisins, Naïve Bayésienne, Arbre de décisions, Forêt Aléatoire, et Réseau de Neurones avec Perceptron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'k_proches_voisins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a997d1ade3a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgestion_donnees\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mk_proches_voisins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnaive_bayesienne\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marbre_decision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'k_proches_voisins'"
     ]
    }
   ],
   "source": [
    "# Importer outils générales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support as metriques\n",
    "from sklearn.metrics import accuracy_score as accu\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from tabulate import tabulate\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# Importer codes spécifiques\n",
    "import gestion_donnees as gd\n",
    "import SVM\n",
    "import k_proches_voisins\n",
    "import naive_bayesienne\n",
    "import arbre_decision\n",
    "import foret_aleatoire\n",
    "import perceptron\n",
    "\n",
    "\n",
    "# Ignorer les warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "# Lire la base de données\n",
    "d_base = pd.read_csv(os.getcwd() + '/info/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix du modèle d'apprentissage\n",
    "\n",
    "Choisir entre les options suivantes quel algorithme d'apprentissage utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c1bdeffb984695bdd71875bf479e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Algorithme :', options=('SVM', 'K-proches_voisins', 'Naive_Bayesienne', 'Arbre_de_decisi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c4df9ee9e24cba8e1e12a447874630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Rechercher hyperparamètres', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithme = widgets.Dropdown(options=['SVM', 'K-proches_voisins', \\\n",
    "                                       'Naive_Bayesienne','Arbre_de_decisions',\\\n",
    "                                       'Foret_Aleatoire','Reseau_de_neurones'],\n",
    "    value='SVM',description='Algorithme :', disabled=False,)\n",
    "rh = widgets.Checkbox(value=False, description='Rechercher hyperparamètres',\n",
    "    disabled=False,indent=False)\n",
    "display(algorithme)\n",
    "display(rh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer l'algorithme choisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algorithme.value == 'Perceptron':\n",
    "    classif = perceptron.Perceptron()\n",
    "    \n",
    "elif algorithme.value == 'SVM':\n",
    "    classif = SVM.SupportVectorMachine()\n",
    "    \n",
    "elif algorithme.value == 'K-proches_voisins': \n",
    "    classif = k_proches_voisins.KProchesVoisins()\n",
    "    \n",
    "elif algorithme.value == 'Naive_Bayesienne': \n",
    "    classif = naive_bayesienne.NaiveBayes()\n",
    "    \n",
    "elif algorithme.value == 'Arbre_decisions': \n",
    "    classif = arbre_decision.ArbreDecision()\n",
    "    \n",
    "elif algorithme.value == 'Foret_Aleatoire': \n",
    "    classif = foret_aleatoire.ForetAleatoire()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traîtement de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données et leur cibles\n",
    "g_donnees = gd.GestionDonnees(d_base)\n",
    "[types, X, t] = g_donnees.lecture_donnees(d_base)\n",
    "    \n",
    "# Séparer les données pour test et train\n",
    "x_tr, x_ts, t_tr, t_ts = g_donnees.sep_donnees(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement\n",
    "\n",
    "On fait l'entraînement de l'algorithme choisi. Cet entrainement dépend du choix fait pour la recherche d'hyperparamètres et du type d'algorithme, ça sera fait avec les libraries de RandomizedSearchCV ou GridSearchCV. Les valeurs d'hyperparamètres à tester sont prédefinis de manière interne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debut de l'entrainement NB avec recherche d'hyperparamètres \n",
      "\n",
      "Paramètres utilisés pour l'entraînement NB : {'alpha': 0.11, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True} \n",
      "\n",
      "Fin de l'entrainement. Réalisé en 15.30 secondes. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "debut_e = time.time() # Heure de debut pour mesurer le temps d'entraînement\n",
    "classif.entrainement(x_tr, t_tr, rh.value)\n",
    "fin_e = time.time() # Heure de fin pour mesurer le temps d'entraînement\n",
    "print('Fin de l\\'entrainement. Réalisé en %.2f secondes.'% (fin_e - debut_e),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions et métriques de performance\n",
    "\n",
    "On fait les prédictions pour les ensembles d'entraînement complet et de test. Ensuite, on calcule les métriques de performance d'accuracy, précision, rappel et F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrique      Train    Test\n",
      "----------  -------  ------\n",
      "Accuracy     0.9757  0.8065\n",
      "Précision    0.9786  0.8019\n",
      "Rappel       0.9759  0.7948\n",
      "F-Beta       0.9757  0.7689\n"
     ]
    }
   ],
   "source": [
    "# Prédictions pour les ensembles d'entraînement et de test\n",
    "predict_tr = classif.prediction(x_tr)\n",
    "predict_ts = classif.prediction(x_ts)\n",
    "\n",
    "# Métriques pour évaluer l'entraînement et test\n",
    "prs_tr, rec_tr, fbeta_tr, _ = metriques(t_tr, predict_tr, average='macro')\n",
    "prs_ts, rec_ts, fbeta_ts, _ = metriques(t_ts, predict_ts, average='macro')\n",
    "acc_tr = accu(t_tr, predict_tr)\n",
    "acc_ts = accu(t_ts, predict_ts)\n",
    "tab_perform = [['Accuracy', acc_tr, acc_ts],['Précision', prs_tr, prs_ts],\\\n",
    "               ['Rappel', rec_tr, rec_ts],['F-Beta', fbeta_tr, fbeta_ts]]\n",
    "print(tabulate(tab_perform, headers=['Métrique', 'Train', 'Test'], \\\n",
    "               floatfmt='.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
